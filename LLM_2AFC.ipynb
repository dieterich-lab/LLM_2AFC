{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d016ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MXFP4 quantization requires triton >= 3.4.0 and kernels installed, we will default to dequantizing the model to bf16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f7bf462fa344cea3dfa72c98538710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL_ID = \"openai/gpt-oss-20b\" \n",
    "# MODEL_ID = \"Qwen/Qwen3-30B-A3B-Instruct-2507-FP8\" \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID, dtype=torch.bfloat16 if torch.cuda.is_available() else None, device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d357f92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping identical pair: Dra., Dra.\n",
      "Skipping identical pair: 2002, 2002\n",
      "Skipping identical pair: Prof., Prof.\n",
      "Skipping identical pair: Drs., Drs.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Prof. Dr., Prof. Dr.\n",
      "Skipping identical pair: Priv.-Doz. Dr. med., Priv.-Doz. Dr. med.\n",
      "Skipping identical pair: DR. MED., DR. MED.\n",
      "Skipping identical pair: 2006, 2006\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Dr.a med. univ., Dr.a med. univ.\n",
      "Skipping identical pair: 12/17, 12/17\n",
      "Skipping identical pair: 12/17, 12/17\n",
      "Skipping identical pair: 12/17, 12/17\n",
      "Skipping identical pair: 01/17, 01/17\n",
      "Skipping identical pair: 10/18, 10/18\n",
      "Skipping identical pair: 11/18, 11/18\n",
      "Skipping identical pair: 01/18, 01/18\n",
      "Skipping identical pair: 06/19, 06/19\n",
      "Skipping identical pair: 9/19, 9/19\n",
      "Skipping identical pair: 9/20, 9/20\n",
      "Skipping identical pair: 9/20, 9/20\n",
      "Skipping identical pair: 11/20, 11/20\n",
      "Skipping identical pair: 03/21, 03/21\n",
      "Skipping identical pair: 1/21, 1/21\n",
      "Skipping identical pair: 1.05., 1.05.\n",
      "Skipping identical pair: 07/21, 07/21\n",
      "Skipping identical pair: 1/19, 1/19\n",
      "Skipping identical pair: 10/14, 10/14\n",
      "Skipping identical pair: 11/14, 11/14\n",
      "Skipping identical pair: 12/14, 12/14\n",
      "Skipping identical pair: 4/16, 4/16\n",
      "Skipping identical pair: 11/18, 11/18\n",
      "Skipping identical pair: Juni, Juni\n",
      "Skipping identical pair: Prof., Prof.\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: Prof. Dr., Prof. Dr.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: 03/23, 03/23\n",
      "Skipping identical pair: 03/23, 03/23\n",
      "Skipping identical pair: 03/23, 03/23\n",
      "Skipping identical pair: 03/23, 03/23\n",
      "Skipping identical pair: 05/23, 05/23\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: Prof. Dr. med, Prof. Dr. med\n",
      "Skipping identical pair: Univ. Prof. Dr. mult., Univ. Prof. Dr. mult.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: 2027-08-02, 2027-08-02\n",
      "Skipping identical pair: 3/27, 3/27\n",
      "Skipping identical pair: 4/27, 4/27\n",
      "Skipping identical pair: 03.17.2027, 03.17.2027\n",
      "Skipping identical pair: MD PhD, MD PhD\n",
      "Skipping identical pair: Prim. Univ. Prof. Dr., Prim. Univ. Prof. Dr.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Doz. Dr., Doz. Dr.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: DGKS, DGKS\n",
      "Skipping identical pair: Prim. Univ. Prof. Dr.Dr., Prim. Univ. Prof. Dr.Dr.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: WinA., WinA.\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: 2019, 2019\n",
      "Skipping identical pair: 2018, 2018\n",
      "Skipping identical pair: Priv. Doz., Priv. Doz.\n",
      "Skipping identical pair: Berlin, Berlin\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: Berlin, Berlin\n",
      "Skipping identical pair: Prof. Dr., Prof. Dr.\n",
      "Skipping identical pair: Prof., Prof.\n",
      "Skipping identical pair: 2018, 2018\n",
      "Skipping identical pair: Dr. med. univers., Dr. med. univers.\n",
      "Skipping identical pair: 2018, 2018\n",
      "Skipping identical pair: 2050, 2050\n",
      "Skipping identical pair: 2044, 2044\n",
      "Skipping identical pair: 2048, 2048\n",
      "Skipping identical pair: PD Dr. Dr., PD Dr. Dr.\n",
      "Skipping identical pair: 2008, 2008\n",
      "Skipping identical pair: 2012, 2012\n",
      "Skipping identical pair: PD Dr., PD Dr.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: 2016, 2016\n",
      "Skipping identical pair: USA, USA\n",
      "Skipping identical pair: Priv.Doz. Dr.in, Priv.Doz. Dr.in\n",
      "Skipping identical pair: Pat.Dr., Pat.Dr.\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: 2007, 2007\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Dr.med., Dr.med.\n",
      "Skipping identical pair: Graz, Graz\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: 6/24, 6/24\n",
      "Skipping identical pair: 9/23, 9/23\n",
      "Skipping identical pair: 9/23, 9/23\n",
      "Skipping identical pair: 6/22, 6/22\n",
      "Skipping identical pair: 9.7.22, 9.7.22\n",
      "Skipping identical pair: Priv.-Doz., Priv.-Doz.\n",
      "Skipping identical pair: 1/26, 1/26\n",
      "Skipping identical pair: 11/28, 11/28\n",
      "Skipping identical pair: 4/29, 4/29\n",
      "Skipping identical pair: 9/29, 9/29\n",
      "Skipping identical pair: 6/29, 6/29\n",
      "Skipping identical pair: 11/29, 11/29\n",
      "Skipping identical pair: 2027, 2027\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Berlin, Berlin\n",
      "Skipping identical pair: 2/18, 2/18\n",
      "Skipping identical pair: 2/18, 2/18\n",
      "Skipping identical pair: 05/18, 05/18\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: OA Dr., OA Dr.\n",
      "Skipping identical pair: 01/22, 01/22\n",
      "Skipping identical pair: 2023, 2023\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Prof. Dr., Prof. Dr.\n",
      "Skipping identical pair: PD Dr., PD Dr.\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: Prof., Prof.\n",
      "Skipping identical pair: Universitätsprofessor Dr. mult. med., Universitätsprofessor Dr. mult. med.\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: Prof. Dr., Prof. Dr.\n",
      "Skipping identical pair: 2008, 2008\n",
      "Skipping identical pair: 2002, 2002\n",
      "Skipping identical pair: 2020, 2020\n",
      "Skipping identical pair: Peru, Peru\n",
      "Skipping identical pair: 2028, 2028\n",
      "Skipping identical pair: 2030, 2030\n",
      "Skipping identical pair: 2035, 2035\n",
      "Skipping identical pair: 2035, 2035\n",
      "Skipping identical pair: 2035, 2035\n",
      "Skipping identical pair: Dr. mult. med., Dr. mult. med.\n",
      "Skipping identical pair: 2018, 2018\n",
      "Skipping identical pair: 08/20, 08/20\n",
      "Skipping identical pair: 12/21, 12/21\n",
      "Skipping identical pair: 9/21, 9/21\n",
      "Skipping identical pair: 12/19, 12/19\n",
      "Skipping identical pair: 3/19, 3/19\n",
      "Skipping identical pair: MD Msc, MD Msc\n",
      "Skipping identical pair: Dr.med., Dr.med.\n",
      "Skipping identical pair: Prof. Dr.Dr., Prof. Dr.Dr.\n",
      "Skipping identical pair: Mag., Mag.\n",
      "Skipping identical pair: Villach, Villach\n",
      "Skipping identical pair: Drª, Drª\n",
      "Skipping identical pair: Mag., Mag.\n",
      "Skipping identical pair: 2017, 2017\n",
      "Skipping identical pair: 2017, 2017\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: Villach, Villach\n",
      "Skipping identical pair: 2017, 2017\n",
      "Skipping identical pair: Oktober, Oktober\n",
      "Skipping identical pair: Doz. DDr. Dr.med.univer., Doz. DDr. Dr.med.univer.\n",
      "Skipping identical pair: Dr.med., Dr.med.\n",
      "Skipping identical pair: Dr.med.univers., Dr.med.univers.\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: 2033, 2033\n",
      "Skipping identical pair: 2002, 2002\n",
      "Skipping identical pair: Prof., Prof.\n",
      "Skipping identical pair: Drs., Drs.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: 15.02.12, 15.02.12\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: Ao., Ao.\n",
      "Skipping identical pair: Uriv.-Prof. Dr. med., Uriv.-Prof. Dr. med.\n",
      "Skipping identical pair: Univ.-Prof. Dr.med., Univ.-Prof. Dr.med.\n",
      "Skipping identical pair: Prof. Dr. med., Prof. Dr. med.\n",
      "Skipping identical pair: Dr  med., Dr  med.\n",
      "Skipping identical pair: 2020-08-03, 2020-08-03\n",
      "Skipping identical pair: 2019, 2019\n",
      "Skipping identical pair: 8/19, 8/19\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: Prof. Dr., Prof. Dr.\n",
      "Skipping identical pair: Prof. Dr. Dr., Prof. Dr. Dr.\n",
      "Skipping identical pair: Juni, Juni\n",
      "Skipping identical pair: 2031, 2031\n",
      "Skipping identical pair: Prof. Dr. med., Prof. Dr. med.\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: 2007, 2007\n",
      "Skipping identical pair: Prof. Dr., Prof. Dr.\n",
      "Skipping identical pair: o.Univ. Prof. Dr., o.Univ. Prof. Dr.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Univ.-Prof. Dr., Univ.-Prof. Dr.\n",
      "Skipping identical pair: Neustadt, Neustadt\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: Neustadt, Neustadt\n",
      "Skipping identical pair: Neustadt, Neustadt\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: MBA, MBA\n",
      "Skipping identical pair: MBA, MBA\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: Neustadt, Neustadt\n",
      "Skipping identical pair: 04/29, 04/29\n",
      "Skipping identical pair: 05/29, 05/29\n",
      "Skipping identical pair: 1995, 1995\n",
      "Skipping identical pair: 1995, 1995\n",
      "Skipping identical pair: 06/29, 06/29\n",
      "Skipping identical pair: PD Dr., PD Dr.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Januar, Januar\n",
      "Skipping identical pair: 2023, 2023\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: PD Dr., PD Dr.\n",
      "Skipping identical pair: 2040, 2040\n",
      "Skipping identical pair: 2040, 2040\n",
      "Skipping identical pair: 2041, 2041\n",
      "Skipping identical pair: 2037, 2037\n",
      "Skipping identical pair: 2044, 2044\n",
      "Skipping identical pair: 2040, 2040\n",
      "Skipping identical pair: 2041, 2041\n",
      "Skipping identical pair: 2037, 2037\n",
      "Skipping identical pair: 2037, 2037\n",
      "Skipping identical pair: 2035, 2035\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: PD Dr. med, PD Dr. med\n",
      "Skipping identical pair: Prof., Prof.\n",
      "Skipping identical pair: 21.04.08, 21.04.08\n",
      "Skipping identical pair: 21.04.08, 21.04.08\n",
      "Skipping identical pair: 24.04.08, 24.04.08\n",
      "Skipping identical pair: PD Dr. med., PD Dr. med.\n",
      "Skipping identical pair: Univ.-Prof. Dr., Univ.-Prof. Dr.\n",
      "Skipping identical pair: Neustadt, Neustadt\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Neustadt, Neustadt\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Neustadt, Neustadt\n",
      "Skipping identical pair: Dr.a., Dr.a.\n",
      "Skipping identical pair: 2020, 2020\n",
      "Skipping identical pair: 2020, 2020\n",
      "Skipping identical pair: 1990, 1990\n",
      "Skipping identical pair: 2025, 2025\n",
      "Skipping identical pair: 2027, 2027\n",
      "Skipping identical pair: 7/23, 7/23\n",
      "Skipping identical pair: Prof. Dr., Prof. Dr.\n",
      "Skipping identical pair: Februar, Februar\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: 2022, 2022\n",
      "Skipping identical pair: Ass.Dr., Ass.Dr.\n",
      "Skipping identical pair: Prof. Dr., Prof. Dr.\n",
      "Skipping identical pair: Neustadt, Neustadt\n",
      "Skipping identical pair: 4/23, 4/23\n",
      "Skipping identical pair: 5/23, 5/23\n",
      "Skipping identical pair: 4/23, 4/23\n",
      "Skipping identical pair: 6/23, 6/23\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: 2009, 2009\n",
      "Skipping identical pair: Prof., Prof.\n",
      "Skipping identical pair: Prof. Dr., Prof. Dr.\n",
      "Skipping identical pair: 2045, 2045\n",
      "Skipping identical pair: 2057, 2057\n",
      "Skipping identical pair: 2059, 2059\n",
      "Skipping identical pair: 2009, 2009\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: PD. Dr. med., PD. Dr. med.\n",
      "Skipping identical pair: Prof. Dr.Dr. med., Prof. Dr.Dr. med.\n",
      "Skipping identical pair: Dr. med., Dr. med.\n",
      "Skipping identical pair: PhD, PhD\n",
      "Skipping identical pair: 5. März2063, 5. März2063\n",
      "Skipping identical pair: Berlin, Berlin\n",
      "Skipping identical pair: Univ-Prof. Dr. med., Univ-Prof. Dr. med.\n",
      "Skipping identical pair: Berlin, Berlin\n",
      "Skipping identical pair: Berlin, Berlin\n",
      "Skipping identical pair: Freiburg, Freiburg\n",
      "Skipping identical pair: Prof. Dr. med., Prof. Dr. med.\n",
      "Skipping identical pair: Prim. DDr., Prim. DDr.\n",
      "Skipping identical pair: Prim. Univ. Prof. Dr., Prim. Univ. Prof. Dr.\n",
      "Skipping identical pair: Ki, Ki\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Doz. Dr., Doz. Dr.\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: DGKS, DGKS\n",
      "Skipping identical pair: 09/24, 09/24\n",
      "Skipping identical pair: PD Dr., PD Dr.\n",
      "Skipping identical pair: Prof., Prof.\n",
      "Skipping identical pair: 4.11.24, 4.11.24\n",
      "Skipping identical pair: 5.11.24, 5.11.24\n",
      "Skipping identical pair: Dr., Dr.\n",
      "Skipping identical pair: Prof. Dr., Prof. Dr.\n",
      "Skipping identical pair: Prof. Dr., Prof. Dr.\n",
      "Skipping identical pair: Prof.Dr. med., Prof.Dr. med.\n",
      "Skipping identical pair: Prof. Dr. med., Prof. Dr. med.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "pattern = re.compile(r\"\\[\\*\\*\\s*(.*?)\\s*\\*\\*\\]\")\n",
    "\n",
    "for filename in os.listdir(\"data/entities_txt\"):\n",
    "    with open(os.path.join(\"data/entities_txt\", filename), 'r') as file:\n",
    "        content = file.read()\n",
    "        \n",
    "        pattern_brat = re.compile(r'^[^\\t]+\\t[^\\t]+\\s+\\d+\\s+\\d+\\t(.+)$')\n",
    "\n",
    "        original_entities = []\n",
    "        fictive_entities = []\n",
    "        with open(os.path.join(\"data/original_ann\", filename), 'r') as file:\n",
    "                lines = file.readlines()\n",
    "                for line in lines:\n",
    "                    match = pattern_brat.match(line.strip())\n",
    "                    if match:\n",
    "                        original_entities.append(match.group(1))\n",
    "                        \n",
    "        with open(os.path.join(\"data/fictive_ann\", filename), 'r') as file:\n",
    "                lines = file.readlines()\n",
    "                for line in lines:\n",
    "                    match = pattern_brat.match(line.strip())\n",
    "                    if match:\n",
    "                        fictive_entities.append(match.group(1))\n",
    "\n",
    "        for m in pattern.finditer(content):\n",
    "            start, end = m.span()\n",
    "            \n",
    "            LETTER = content[:start] + \"[** ENTITY_SLOT **]\" + content[end:]\n",
    "            \n",
    "            # Pull the next pair\n",
    "            original_entity = original_entities.pop(0)\n",
    "            fictive_entity   = fictive_entities.pop(0)\n",
    "            if original_entity == fictive_entity:\n",
    "                print(f\"Skipping identical pair: {original_entity}, {fictive_entity}\")\n",
    "                continue\n",
    "\n",
    "            # Randomly decide which option slot gets the real original\n",
    "            if random.random() < 0.5:\n",
    "                OPTION_A, OPTION_B = original_entity, fictive_entity\n",
    "                truth_label, truth_text = \"A\", original_entity\n",
    "            else:\n",
    "                OPTION_A, OPTION_B = fictive_entity, original_entity\n",
    "                truth_label, truth_text = \"B\", original_entity\n",
    "            \n",
    "            SYSTEM_PROMPT = \"\"\"2AFC LINKAGE EVALUATOR\n",
    "            You evaluate a two-alternative forced-choice (2AFC) linkage task on doctor letters.\n",
    "\n",
    "            Input:\n",
    "            • One letter with a single masked slot: [**ENTITY_SLOT**]\n",
    "            • Two candidates labeled A) and B)\n",
    "\n",
    "            Task: Choose the candidate that most likely belongs into masked slot given the context of the letter.\n",
    "\n",
    "            Output (STRICT):\n",
    "            You have to return exactly one capital letter — A or B — with nothing else (no spaces, punctuation, or newlines).\n",
    "            You can not Answer with None.\n",
    "            \"\"\"\n",
    "\n",
    "            # ---- Beispieltext zur Verarbeitung ----\n",
    "            INPUT_TEXT = f\"\"\"\"\n",
    "            DOCTOR LETTER:\n",
    "                {LETTER}\n",
    "            OPTIONS:\n",
    "                A) {OPTION_A}\n",
    "                B) {OPTION_B}\n",
    "            \"\"\"\n",
    "                \n",
    "            def build_input(tokenizer, INPUT_TEXT: str):\n",
    "                messages = [\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": INPUT_TEXT},\n",
    "                ]\n",
    "                \n",
    "                if hasattr(tokenizer, \"apply_chat_template\"):\n",
    "                    return tokenizer.apply_chat_template(\n",
    "                        messages, add_generation_prompt=True, return_tensors=\"pt\", reasoning_effort=\"low\"\n",
    "                    )\n",
    "                \n",
    "            # ---- Hauptverarbeitung ----\n",
    "            input_ids = build_input(tokenizer, INPUT_TEXT).to(model.device)\n",
    "\n",
    "\n",
    "            gen_kwargs = dict(\n",
    "                max_new_tokens=1000,\n",
    "                do_sample=False,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out = model.generate(input_ids, **gen_kwargs)\n",
    "\n",
    "            # Slice off the prompt part\n",
    "            gen_ids = out[0][input_ids.shape[-1]:]\n",
    "            raw = tokenizer.decode(gen_ids, skip_special_tokens=False).strip()\n",
    "\n",
    "            # Generic: capture ANY channel blocks\n",
    "            def grab_block(text: str, kind: str):\n",
    "                start_tag = f\"<|channel|>{kind}<|message|>\"\n",
    "                i = text.rfind(start_tag)\n",
    "                if i == -1:\n",
    "                    return None\n",
    "                i += len(start_tag)\n",
    "                # find nearest terminator after i\n",
    "                j_end = text.find(\"<|end|>\", i)\n",
    "                j_ret = text.find(\"<|return|>\", i)\n",
    "                j_candidates = [x for x in (j_end, j_ret) if x != -1]\n",
    "                j = min(j_candidates) if j_candidates else len(text)\n",
    "                return text[i:j].strip()\n",
    "\n",
    "            analysis_text = grab_block(raw, \"analysis\")\n",
    "            final_text = grab_block(raw, \"final\")\n",
    "\n",
    "            output_data = {\n",
    "                \"letter\": LETTER,\n",
    "                \"option_a\": OPTION_A,\n",
    "                \"option_b\": OPTION_B,\n",
    "                \"resoning\": analysis_text,\n",
    "                \"choice\": final_text,\n",
    "                \"truth\":truth_label,\n",
    "                \"is_correct\": (final_text == truth_label)\n",
    "            }\n",
    "\n",
    "            output_file = os.path.join(\"LLM_2AFC_output\", f\"result_{os.path.splitext(filename)[0]}_{m.start()}.json\")\n",
    "\n",
    "            with open(output_file, 'w') as f:\n",
    "                json.dump(output_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03e1df7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/18 10/18\n",
      "9/19 9/19\n",
      "12/21 12/21\n",
      "WinA. WinA.\n",
      "Dr. med. Dr. med.\n",
      "2/18 2/18\n",
      "2031 2031\n",
      "Mag. Mag.\n",
      "7/23 7/23\n",
      "Neustadt Neustadt\n",
      "2027 2027\n",
      "DR. MED. DR. MED.\n",
      "Dr.med.univers. Dr.med.univers.\n",
      "2018 2018\n",
      "Neustadt Neustadt\n",
      "2041 2041\n",
      "21.04.08 21.04.08\n",
      "Dr. med. Dr. med.\n",
      "11/28 11/28\n",
      "Freiburg Freiburg\n",
      "Prof. Dr. med. Prof. Dr. med.\n",
      "Neustadt Neustadt\n",
      "4/27 4/27\n",
      "03/23 03/23\n",
      "OA Dr. OA Dr.\n",
      "Dr. Dr.\n",
      "Prof. Prof.\n",
      "01/22 01/22\n",
      "Dr. Dr.\n",
      "03/23 03/23\n",
      "Neustadt Neustadt\n",
      "Univ.-Prof. Dr. Univ.-Prof. Dr.\n",
      "Doz. Dr. Doz. Dr.\n",
      "11/14 11/14\n",
      "1995 1995\n",
      "Univ-Prof. Dr. med. Univ-Prof. Dr. med.\n",
      "2007 2007\n",
      "Prim. Univ. Prof. Dr. Prim. Univ. Prof. Dr.\n",
      "Prof. Dr. Prof. Dr.\n",
      "2019 2019\n",
      "2020 2020\n",
      "2037 2037\n",
      "Priv. Doz. Priv. Doz.\n",
      "Neustadt Neustadt\n",
      "Univ. Prof. Dr. mult. Univ. Prof. Dr. mult.\n",
      "Dr. Dr.\n",
      "PD. Dr. med. PD. Dr. med.\n",
      "03/23 03/23\n",
      "4/23 4/23\n",
      "DGKS DGKS\n",
      "Dr. Dr.\n",
      "1995 1995\n",
      "Prof. Dr.Dr. med. Prof. Dr.Dr. med.\n",
      "Univ.-Prof. Dr. Univ.-Prof. Dr.\n",
      "1.05. 1.05.\n",
      "PD Dr. med. PD Dr. med.\n",
      "Prof. Dr. med. Prof. Dr. med.\n",
      "2048 2048\n",
      "05/23 05/23\n",
      "2007 2007\n",
      "Dr. Dr.\n",
      "Juni Juni\n",
      "2035 2035\n",
      "9/23 9/23\n",
      "04/29 04/29\n",
      "2035 2035\n",
      "Prim. Univ. Prof. Dr.Dr. Prim. Univ. Prof. Dr.Dr.\n",
      "2044 2044\n",
      "Peru Peru\n",
      "2027 2027\n",
      "08/20 08/20\n",
      "Villach Villach\n",
      "Dr. Dr.\n",
      "Ki Ki\n",
      "24.04.08 24.04.08\n",
      "Neustadt Neustadt\n",
      "Dr. Dr.\n",
      "Dr. Dr.\n",
      "Dr. Dr.\n",
      "12/17 12/17\n",
      "Dr. Dr.\n",
      "15.02.12 15.02.12\n",
      "Dr. med. Dr. med.\n",
      "Dr. Dr.\n",
      "Dr. Dr.\n",
      "Prof. Dr. med Prof. Dr. med\n",
      "Dr. med. Dr. med.\n",
      "Dr. med. univers. Dr. med. univers.\n",
      "2002 2002\n",
      "2023 2023\n",
      "2050 2050\n",
      "Dr. Dr.\n",
      "Februar Februar\n",
      "Dr. med. Dr. med.\n",
      "Prof. Dr. Prof. Dr.\n",
      "11/18 11/18\n",
      "9/20 9/20\n",
      "Dr. med. Dr. med.\n",
      "6/22 6/22\n",
      "Neustadt Neustadt\n",
      "2012 2012\n",
      "2030 2030\n",
      "Dr. Dr.\n",
      "Mag. Mag.\n",
      "Oktober Oktober\n",
      "Prof. Prof.\n",
      "4/23 4/23\n",
      "Dr. Dr.\n",
      "Dr. Dr.\n",
      "9/20 9/20\n",
      "Dr.med. Dr.med.\n",
      "Doz. DDr. Dr.med.univer. Doz. DDr. Dr.med.univer.\n",
      "2033 2033\n",
      "Dr. Dr.\n",
      "Dr. med. Dr. med.\n",
      "Dr. med. Dr. med.\n",
      "Dr. Dr.\n",
      "3/27 3/27\n",
      "Dr. med. Dr. med.\n",
      "2002 2002\n",
      "Dr. med. Dr. med.\n",
      "Villach Villach\n",
      "o.Univ. Prof. Dr. o.Univ. Prof. Dr.\n",
      "Prof. Dr. med. Prof. Dr. med.\n",
      "01/17 01/17\n",
      "2035 2035\n",
      "Dr. med. Dr. med.\n",
      "Graz Graz\n",
      "2040 2040\n",
      "Dr. Dr.\n",
      "Berlin Berlin\n",
      "03/21 03/21\n",
      "Dr. med. Dr. med.\n",
      "Januar Januar\n",
      "PD Dr. PD Dr.\n",
      "Prof. Dr. Prof. Dr.\n",
      "03.17.2027 03.17.2027\n",
      "Dra. Dra.\n",
      "2008 2008\n",
      "Dr. Dr.\n",
      "Dr. Dr.\n",
      "2017 2017\n",
      "2018 2018\n",
      "Drs. Drs.\n",
      "Dr. Dr.\n",
      "Prof. Dr.Dr. Prof. Dr.Dr.\n",
      "Drs. Drs.\n",
      "Dr. med. Dr. med.\n",
      "MBA MBA\n",
      "6/29 6/29\n",
      "Prof. Dr. Prof. Dr.\n",
      "06/19 06/19\n",
      "09/24 09/24\n",
      "2023 2023\n",
      "2018 2018\n",
      "9/23 9/23\n",
      "9/29 9/29\n",
      "MBA MBA\n",
      "2059 2059\n",
      "2037 2037\n",
      "12/14 12/14\n",
      "PhD PhD\n",
      "4.11.24 4.11.24\n",
      "Priv.-Doz. Priv.-Doz.\n",
      "Prof. Dr. Prof. Dr.\n",
      "PD Dr. PD Dr.\n",
      "Dr. med. Dr. med.\n",
      "Prof. Dr. med. Prof. Dr. med.\n",
      "Neustadt Neustadt\n",
      "2040 2040\n",
      "Prof. Prof.\n",
      "Dr.med. Dr.med.\n",
      "05/29 05/29\n",
      "1990 1990\n",
      "5.11.24 5.11.24\n",
      "Dr. med. Dr. med.\n",
      "Prof. Dr. Prof. Dr.\n",
      "1/19 1/19\n",
      "10/14 10/14\n",
      "Juni Juni\n",
      "2022 2022\n",
      "2028 2028\n",
      "2009 2009\n",
      "Dr. Dr.\n",
      "9/21 9/21\n",
      "Dr. Dr.\n",
      "PD Dr. PD Dr.\n",
      "12/17 12/17\n",
      "2037 2037\n",
      "2018 2018\n",
      "2035 2035\n",
      "2040 2040\n",
      "12/17 12/17\n",
      "2041 2041\n",
      "12/19 12/19\n",
      "06/29 06/29\n",
      "Ass.Dr. Ass.Dr.\n",
      "2019 2019\n",
      "PD Dr. med PD Dr. med\n",
      "2017 2017\n",
      "Dr. Dr.\n",
      "Dr. Dr.\n",
      "Prof.Dr. med. Prof.Dr. med.\n",
      "Berlin Berlin\n",
      "Dr. Dr.\n",
      "Dr. Dr.\n",
      "Prof. Dr. Dr. Prof. Dr. Dr.\n",
      "2020-08-03 2020-08-03\n",
      "Uriv.-Prof. Dr. med. Uriv.-Prof. Dr. med.\n",
      "Prof. Prof.\n",
      "03/23 03/23\n",
      "3/19 3/19\n",
      "Dr.med. Dr.med.\n",
      "8/19 8/19\n",
      "5. März2063 5. März2063\n",
      "Prof. Dr. Prof. Dr.\n",
      "PD Dr. PD Dr.\n",
      "07/21 07/21\n",
      "11/20 11/20\n",
      "Drª Drª\n",
      "Berlin Berlin\n",
      "Dr. med. Dr. med.\n",
      "Dr. med. Dr. med.\n",
      "Dr. Dr.\n",
      "11/18 11/18\n",
      "Prof. Prof.\n",
      "2002 2002\n",
      "Prof. Dr. Prof. Dr.\n",
      "Dr.a. Dr.a.\n",
      "11/29 11/29\n",
      "Dr.a med. univ. Dr.a med. univ.\n",
      "Universitätsprofessor Dr. mult. med. Universitätsprofessor Dr. mult. med.\n",
      "Dr  med. Dr  med.\n",
      "PD Dr. Dr. PD Dr. Dr.\n",
      "6/24 6/24\n",
      "Prim. Univ. Prof. Dr. Prim. Univ. Prof. Dr.\n",
      "2016 2016\n",
      "Dr. Dr.\n",
      "Dr. Dr.\n",
      "2008 2008\n",
      "4/29 4/29\n",
      "Berlin Berlin\n",
      "2025 2025\n",
      "1/26 1/26\n",
      "MD PhD MD PhD\n",
      "PD Dr. PD Dr.\n",
      "5/23 5/23\n",
      "Prof. Dr. Prof. Dr.\n",
      "Prof. Prof.\n",
      "2045 2045\n",
      "05/18 05/18\n",
      "4/16 4/16\n",
      "2020 2020\n",
      "2006 2006\n",
      "Doz. Dr. Doz. Dr.\n",
      "Dr. mult. med. Dr. mult. med.\n",
      "2/18 2/18\n",
      "Dr. med. Dr. med.\n",
      "Dr. Dr.\n",
      "9.7.22 9.7.22\n",
      "6/23 6/23\n",
      "01/18 01/18\n",
      "MD Msc MD Msc\n",
      "2057 2057\n",
      "Berlin Berlin\n",
      "Dr. med. Dr. med.\n",
      "Dr. med. Dr. med.\n",
      "Priv.-Doz. Dr. med. Priv.-Doz. Dr. med.\n",
      "Univ.-Prof. Dr.med. Univ.-Prof. Dr.med.\n",
      "2017 2017\n",
      "USA USA\n",
      "Prof. Prof.\n",
      "2020 2020\n",
      "Priv.Doz. Dr.in Priv.Doz. Dr.in\n",
      "2044 2044\n",
      "DGKS DGKS\n",
      "Pat.Dr. Pat.Dr.\n",
      "Dr. med. Dr. med.\n",
      "Prof. Dr. Prof. Dr.\n",
      "2009 2009\n",
      "Dr. Dr.\n",
      "Prim. DDr. Prim. DDr.\n",
      "1/21 1/21\n",
      "Prof. Dr. Prof. Dr.\n",
      "Ao. Ao.\n",
      "2027-08-02 2027-08-02\n",
      "Dr. Dr.\n",
      "Prof. Prof.\n",
      "Prof. Dr. Prof. Dr.\n",
      "21.04.08 21.04.08\n",
      "Berlin Berlin\n",
      "Correct predictions: 729\n",
      "Incorrect predictions: 707\n",
      "Accuracy: 50.77%\n",
      "Same option: 291\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "same = 0\n",
    "\n",
    "directory = \"LLM_2AFC_output\"\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(directory, filename), 'r') as f:\n",
    "            data = json.load(f)\n",
    "            op_a = data[\"option_a\"]\n",
    "            ob_b = data[\"option_b\"]\n",
    "            same += op_a == ob_b\n",
    "            if op_a == ob_b:\n",
    "                print(op_a, ob_b)\n",
    "            if data[\"is_correct\"]:\n",
    "                correct_count += 1\n",
    "            else:\n",
    "                incorrect_count += 1\n",
    "\n",
    "print(f\"Correct predictions: {correct_count}\")\n",
    "print(f\"Incorrect predictions: {incorrect_count}\")\n",
    "print(f\"Accuracy: {correct_count / (correct_count + incorrect_count):.2%}\")\n",
    "print(f\"Same option: {same:}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df1cbf",
   "metadata": {},
   "source": [
    "# 2AFC stats from n (trials) and k (correct)\n",
    "- Accuracy\n",
    "- Standard error\n",
    "- Wilson 95% CI\n",
    "- 90% Wilson CI (for equivalence checks)\n",
    "- Binomial test vs 50%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed630d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 1436, k = 729\n",
      "Accuracy (p̂)      : 50.77%\n",
      "Std. error         : 0.013193  (1.319 percentage points)\n",
      "95% CI (Exact Clopper–Pearson): [48.15%, 53.38%]\n",
      "Binomial test vs 50%: two-sided p = 0.579 | one-sided p(>0.5) = 0.290\n",
      "90% CI (Exact 90% (Clopper–Pearson)): [48.56%, 52.97%]\n",
      "Equivalence margin  : ±5.0 pp → window [45.00%, 55.00%]\n",
      "Equivalence result  : PASS (inside window)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "def accuracy(n, k):\n",
    "    return k / n\n",
    "\n",
    "def se_proportion(n, k):\n",
    "    p = k / n\n",
    "    return math.sqrt(p * (1 - p) / n)\n",
    "\n",
    "def wilson_ci(n, k, alpha=0.05):\n",
    "    # Wilson score interval\n",
    "    z = {0.10: 1.2815515655446004, 0.05: 1.6448536269514722, 0.025: 1.959963984540054}[alpha/2]\n",
    "    p = k / n\n",
    "    denom = 1 + (z*z)/n\n",
    "    center = (p + (z*z)/(2*n)) / denom\n",
    "    half = (z * math.sqrt((p*(1-p)/n) + (z*z)/(4*n*n))) / denom\n",
    "    return (center - half, center + half)\n",
    "\n",
    "def normal_binom_test_vs_half(n, k):\n",
    "    \"\"\"\n",
    "    Continuity-corrected normal approx for H0: p = 0.5.\n",
    "    Returns (one_sided_p_gt, two_sided_p).\n",
    "    \"\"\"\n",
    "    mu = n / 2\n",
    "    sigma = math.sqrt(n / 4)\n",
    "    # For upper-tail (k >= observed), use k - 0.5 continuity correction\n",
    "    z = ((k - 0.5) - mu) / sigma\n",
    "    # Survival function of standard normal using erf\n",
    "    def norm_sf(z):\n",
    "        cdf = 0.5 * (1 + math.erf(z / math.sqrt(2)))\n",
    "        return 1 - cdf\n",
    "    one_sided = norm_sf(z)              # P(K >= k | H0)\n",
    "    # two-sided: double the smaller tail\n",
    "    cdf_lower = 1 - one_sided           # P(K <= k-1 | H0, with CC)\n",
    "    two_sided = 2 * min(cdf_lower, one_sided)\n",
    "    return one_sided, two_sided\n",
    "\n",
    "def try_exact_binom(n, k):\n",
    "    \"\"\"\n",
    "    Try to compute exact binomial test & exact (Clopper–Pearson) CI via SciPy.\n",
    "    \"\"\"\n",
    "    from scipy.stats import binomtest, beta\n",
    "    # Exact test vs 0.5\n",
    "    exact_test_two = binomtest(k, n, p=0.5, alternative='two-sided').pvalue\n",
    "    exact_test_one  = binomtest(k, n, p=0.5, alternative='greater').pvalue\n",
    "    # Exact 95% CI (Clopper–Pearson)\n",
    "    alpha = 0.05\n",
    "    if k == 0:\n",
    "        cp_lo = 0.0\n",
    "    else:\n",
    "        cp_lo = beta.ppf(alpha/2, k, n - k + 1)\n",
    "    if k == n:\n",
    "        cp_hi = 1.0\n",
    "    else:\n",
    "        cp_hi = beta.ppf(1 - alpha/2, k + 1, n - k)\n",
    "    # Exact 90% CI\n",
    "    alpha90 = 0.10\n",
    "    if k == 0:\n",
    "        cp_lo_90 = 0.0\n",
    "    else:\n",
    "        cp_lo_90 = beta.ppf(alpha90/2, k, n - k + 1)\n",
    "    if k == n:\n",
    "        cp_hi_90 = 1.0\n",
    "    else:\n",
    "        cp_hi_90 = beta.ppf(1 - alpha90/2, k + 1, n - k)\n",
    "    return {\n",
    "        \"p_two_sided\": exact_test_two,\n",
    "        \"p_one_sided\": exact_test_one,\n",
    "        \"cp95\": (cp_lo, cp_hi),\n",
    "        \"cp90\": (cp_lo_90, cp_hi_90),\n",
    "    }\n",
    "\n",
    "def summarize(n, k, equivalence_margin=0.05):\n",
    "    p_hat = accuracy(n, k)\n",
    "    se = se_proportion(n, k)\n",
    "\n",
    "    # Wilson 95% and 90%\n",
    "    wilson95 = wilson_ci(n, k, alpha=0.05)\n",
    "    wilson90 = wilson_ci(n, k, alpha=0.10)\n",
    "\n",
    "    # Tests vs 50%\n",
    "    exact = try_exact_binom(n, k)\n",
    "    if exact:\n",
    "        p_two = exact[\"p_two_sided\"]\n",
    "        p_one = exact[\"p_one_sided\"]\n",
    "        ci95 = exact[\"cp95\"]\n",
    "        ci90 = exact[\"cp90\"]\n",
    "        ci_label = \"Exact Clopper–Pearson\"\n",
    "        ci90_label = \"Exact 90% (Clopper–Pearson)\"\n",
    "    else:\n",
    "        p_one, p_two = normal_binom_test_vs_half(n, k)\n",
    "        ci95 = wilson95\n",
    "        ci90 = wilson90\n",
    "        ci_label = \"Wilson (approx.)\"\n",
    "        ci90_label = \"Wilson 90% (approx.)\"\n",
    "\n",
    "    # Equivalence check: is the entire 90% CI inside [0.5 ± margin]?\n",
    "    eq_low, eq_high = 0.5 - equivalence_margin, 0.5 + equivalence_margin\n",
    "    equivalent_to_chance = (ci90[0] >= eq_low) and (ci90[1] <= eq_high)\n",
    "\n",
    "    # Pretty print\n",
    "    def pct(x): return f\"{100*x:.2f}%\"\n",
    "    print(f\"n = {n}, k = {k}\")\n",
    "    print(f\"Accuracy (p̂)      : {pct(p_hat)}\")\n",
    "    print(f\"Std. error         : {se:.6f}  ({100*se:.3f} percentage points)\")\n",
    "    print(f\"95% CI ({ci_label}): [{pct(ci95[0])}, {pct(ci95[1])}]\")\n",
    "    print(f\"Binomial test vs 50%: two-sided p = {p_two:.3f} | one-sided p(>0.5) = {p_one:.3f}\")\n",
    "    print(f\"90% CI ({ci90_label}): [{pct(ci90[0])}, {pct(ci90[1])}]\")\n",
    "    print(f\"Equivalence margin  : ±{100*equivalence_margin:.1f} pp → \"\n",
    "          f\"window [{pct(eq_low)}, {pct(eq_high)}]\")\n",
    "    print(f\"Equivalence result  : \"\n",
    "          f\"{'PASS (inside window)' if equivalent_to_chance else 'FAIL (touches/exceeds window)'}\")\n",
    "\n",
    "summarize(n=1436, k=729, equivalence_margin=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ddab0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surrogates",
   "language": "python",
   "name": "surrogates"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
